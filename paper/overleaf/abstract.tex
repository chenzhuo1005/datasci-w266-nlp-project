This paper investigates the impact of retrieval-augmented generation on the performance of large language models (LLMs) in Open-Domain Question Answering (ODQA). We incorporate an external knowledge augmentation system leveraging the PAQ dataset, which enriches LLMs like Flan-T5 and Llama-2-13B-chat with real-time access to over 1.4 million question-answer pairs. By enabling dynamic retrieval of relevant information, we aim to overcome the inherent limitations of LLMs related to fixed knowledge bases and context length constraints. The study evaluates enhancements in accuracy, employing metrics such as Exact Match, F1, and Rouge scores. Our results demonstrate that retrieval-augmented techniques significantly improve the answer quality across various LLMs (\eg, $8.45 \rightarrow 35.48$ EM on Flan-T5-large), highlighting the potential of integrating these systems to extend the capabilities and applicability of traditional neural language models in complex question answering tasks.\footnote{Code and datasets are available at \url{https://github.com/chenzhuo1005/datasci-w266-nlp-project}.}